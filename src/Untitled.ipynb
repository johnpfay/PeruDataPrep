{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis import GIS\n",
    "gis = GIS('pro')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all assets in the folder\n",
    "items = gis.users.me.items(folder='Peru_raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify X and Y field names\n",
    "x_fld = \"Point_X\"\n",
    "y_fld = \"Point_Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_log = open('log.txt','w')\n",
    "the_log.write('File,Type,Valid,Coerced,Total_rows,Numeric_coords,Valid_coords\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Existing items\n",
    "existing_items = [item.title for item in gis.users.me.items(folder = 'Peru_derived_layers')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy_of_vanGeen_WHO_AppendixB.xlsx,Microsoft Excel,Invalid fields\n",
      "Complete_Environmental_Sample_Sheet.xlsx,Microsoft Excel,\n",
      "River_fish_hg_enviro_gps.xlsx,Microsoft Excel,Invalid fields\n",
      "suspar.xlsx,Microsoft Excel,Invalid fields\n",
      "Compiled_Study_Sampling_Points3.csv,CSV,Invalid fields\n",
      "PAM_Inventory_All_2016_V2.csv,CSV,Invalid encoding\n",
      "\n",
      "FishAnalysisLagCategories.csv,CSV,\n",
      "Mercury_Complete_Env_Sample_Sheet_LDAS.csv,CSV,\n",
      "baseline_data_20171109.dta,CSV,\n",
      "baseline_data_20171116.dta,CSV,\n",
      "followup_data_20171109.dta,CSV,\n",
      "followup_data_20171116.dta,CSV,Invalid encoding\n",
      "\n",
      "ASSET_ENG_031016_CLEANED.DTA,CSV,Invalid fields\n",
      "economic_data.dta,CSV,Invalid encoding\n",
      "\n",
      "FINAL_Hunt_follow-up_hair_results_JHG_10-12-16.dta,CSV,Invalid encoding\n",
      "\n",
      "FISH_CONSUMPTION_ENG_031016_CLEANED_CW.DTA,CSV,Invalid fields\n",
      "HgBlood_Baseline_20170918.dta,CSV,Invalid encoding\n",
      "\n",
      "HgBlood_FollowUp_20170918.dta,CSV,Invalid encoding\n",
      "\n",
      "HH_Mining.dta,CSV,Invalid encoding\n",
      "\n",
      "HH_ROSTER_ENG_031016_CLEANED.DTA,CSV,Invalid encoding\n",
      "\n",
      "METADATA_030316_CLEANED.DTA,CSV,Invalid encoding\n",
      "\n",
      "occupation_data.dta,CSV,Invalid fields\n",
      "SENTINEL_DATA_PUFA_AND_HAIR_MERGED_ENG_16DEC2016.DTA,CSV,Invalid encoding\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for the_item in items:\n",
    "    var_name = the_item.name; theStr = f\"{var_name},\"\n",
    "    var_type = the_item.type; theStr += f\"{var_type},\"\n",
    "    theName = the_item.name.split(\".\")[0]\n",
    "    if theName in existing_items:\n",
    "        print(theStr)\n",
    "        continue\n",
    "    \n",
    "    #Get the data from the item\n",
    "    if var_type == 'Microsoft Excel':\n",
    "        df = pd.read_excel(the_item.get_data())\n",
    "    elif var_type == 'CSV':\n",
    "        try:\n",
    "            df = pd.read_csv(the_item.get_data(),encoding='utf-8')\n",
    "        except:\n",
    "            theStr+=\"Invalid encoding\\n\"\n",
    "            the_log.write(theStr)\n",
    "            print(theStr)\n",
    "            continue\n",
    "    else: \n",
    "        theStr += \"Invalid type\\n\"\n",
    "        the_log.write(theStr,end='')\n",
    "        print(theStr)\n",
    "        continue\n",
    "\n",
    "    #Search for coordinate fields\n",
    "    if not(x_fld in df.columns and y_fld in df.columns): \n",
    "        theStr += f\"Invalid fields\\n\"\n",
    "        the_log.write(theStr)\n",
    "        print(theStr,end='')\n",
    "        continue\n",
    "\n",
    "    #Extract just coordinate columns\n",
    "    df_coords = df.loc[:,[x_fld,y_fld]]\n",
    "\n",
    "    #Check dtype of coordinate fields, convert if needed\n",
    "    if df_coords[x_fld].dtype != np.float or df_coords[x_fld].dtype != np.float: \n",
    "        theStr += f\"Valid,Coerced,\"\n",
    "        #Convert to number\n",
    "        df_coords[x_fld] = pd.to_numeric(df_coords[x_fld],errors='coerce')\n",
    "        df_coords[y_fld] = pd.to_numeric(df_coords[y_fld],errors='coerce')\n",
    "        #Remove bad rows\n",
    "        df_coords.dropna(how='any',inplace=True)\n",
    "    else:\n",
    "        theStr += \"Valid,Float,\"\n",
    "        \n",
    "    #Add the shape to the output\n",
    "    theStr += f\"{df_coords.shape[0]},\"\n",
    "\n",
    "    #Filter for records with valid values\n",
    "    xy_mask = (df_coords[x_fld]>=-180) & (df_coords[x_fld]<=180) & (df_coords[y_fld]>=-90) & (df_coords[x_fld]<=90)\n",
    "    df_valid = df_coords.loc[xy_mask].reset_index(drop=True)\n",
    "    theStr += f\",{df_valid.shape[0]}\\n\"\n",
    "    the_log.write(theStr)\n",
    "    print(theStr,end='')\n",
    "\n",
    "    #Convert to spatial dataframe\n",
    "    sdf = pd.DataFrame.spatial.from_xy(df_valid,x_column=x_fld,y_column=y_fld)\n",
    "\n",
    "    #Upload to AGOL\n",
    "    theName = the_item.name.split(\".\")[0]\n",
    "    the_lyr = sdf.spatial.to_featurelayer(title=theName,folder='Peru_derived_layers')\n",
    "    the_lyr.share(groups=['a81478c63d434e33829d2168c4dfdd93'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_item.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\jpfay\\\\AppData\\\\Local\\\\Temp\\\\PAM_Inventory_All_2016_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
