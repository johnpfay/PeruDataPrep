{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from arcgis import GIS\n",
    "gis = GIS('pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary of file lists (by extension)\n",
    "thePath = \"C:/Users/jpfay/Box/Files to Process\"\n",
    "files = {}\n",
    "for ext in ['csv','xlsx','dta','DTA']:\n",
    "    files[ext] = [path for path in Path(thePath).rglob(\"*.\"+ext)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy of vanGeen_WHO_AppendixB exists. skipping\n",
      "Complete Environmental Sample Sheet exists. skipping\n",
      "River fish hg enviro gps exists. skipping\n",
      "suspar exists. skipping\n"
     ]
    }
   ],
   "source": [
    "#Process all excel files\n",
    "for the_file in files['xlsx']:\n",
    "    #Get the filename (less the extension)\n",
    "    file_name = os.path.basename(the_file).split(\".\")[0]\n",
    "    #Check to see whether it exists already\n",
    "    if gis.content.search(f\"{file_name} type:Microsoft Excel\"):\n",
    "           print(f\"{file_name} exists. skipping\")\n",
    "           continue\n",
    "    #Set the properties\n",
    "    the_properties = {'type':\"Microsoft Excel\"}\n",
    "    #Upload the dataset\n",
    "    the_table = gis.content.add(item_properties=the_properties,\n",
    "                                data=str(the_file),\n",
    "                                folder='Peru_raw_data')\n",
    "    #Share the dataset\n",
    "    the_table.share('a81478c63d434e33829d2168c4dfdd93')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Compiled Study Sampling Points3\n",
      "Processing PAM Inventory All 2016_V2\n",
      "Processing FishAnalysisLagCategories\n",
      "Processing Mercury Complete Env Sample Sheet_LDAS\n"
     ]
    }
   ],
   "source": [
    "#Process all csv files\n",
    "for the_file in files['csv']:\n",
    "    #Get the filename (less the extension)\n",
    "    file_name = os.path.basename(the_file).split(\".\")[0]\n",
    "    #Check to see whether it exists already\n",
    "    if gis.content.search(f\"{file_name} type:CSV\"):\n",
    "           print(f\"{file_name} exists. skipping\")\n",
    "           continue\n",
    "    #Process\n",
    "    print(f'Processing {file_name}')\n",
    "    #Set the properties\n",
    "    the_properties = {'type':\"CSV\"}\n",
    "    #Upload the dataset\n",
    "    the_table = gis.content.add(item_properties=the_properties,\n",
    "                                data=str(the_file),\n",
    "                                folder='Peru_raw_data')\n",
    "    #Share the dataset\n",
    "    the_table.share('a81478c63d434e33829d2168c4dfdd93')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing baseline_data_20171109_dta\n",
      "Processing baseline_data_20171116_dta\n",
      "Processing followup_data_20171109_dta\n",
      "Processing followup_data_20171116_dta\n",
      "Processing ASSET_ENG_031016_CLEANED_dta\n",
      "Processing economic_data_dta\n",
      "Processing FINAL_Hunt follow-up hair results_JHG 10-12-16_dta\n",
      "Processing FISH_CONSUMPTION_ENG_031016_CLEANED_CW_dta\n",
      "Processing HgBlood_Baseline_20170918_dta\n",
      "Processing HgBlood_FollowUp_20170918_dta\n",
      "Processing HH_Mining_dta\n",
      "Processing HH_ROSTER_ENG_031016_CLEANED_dta\n",
      "Processing METADATA_030316_CLEANED_dta\n",
      "Processing occupation_data_dta\n",
      "Processing SENTINEL_DATA_PUFA_AND_HAIR_MERGED_ENG_16DEC2016_dta\n"
     ]
    }
   ],
   "source": [
    "#Process all dta files\n",
    "for the_file in files['dta']:\n",
    "    #Get the filename (less the extension, then add \"_dta\")\n",
    "    file_name = os.path.basename(the_file).split(\".\")[0]\n",
    "    file_name += '_dta'\n",
    "\n",
    "    #Convert to pandas dataframe\n",
    "    df = pd.read_stata(the_file)\n",
    "\n",
    "    #Export as a local csv file\n",
    "    file_name_csv = f'{file_name}.csv'\n",
    "    df.to_csv(file_name_csv,index=False)\n",
    "\n",
    "    #Check to see whether it exists already\n",
    "    if gis.content.search(f\"{file_name} type:CSV\"):\n",
    "           print(f\"{file_name} exists. skipping\")\n",
    "           continue\n",
    "    #Process\n",
    "    print(f'Processing {file_name}')\n",
    "    #Set the properties\n",
    "    the_properties = {'type':\"CSV\"}\n",
    "    #Upload the dataset\n",
    "    the_table = gis.content.add(item_properties=the_properties,\n",
    "                                data=str(the_file),\n",
    "                                folder='Peru_raw_data')\n",
    "    #Share the dataset\n",
    "    the_table.share('a81478c63d434e33829d2168c4dfdd93')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
